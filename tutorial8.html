<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.550">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Quang Mai">
<meta name="dcterms.date" content="2024-03-06">

<title>Nonresponse Rates and Nonresponse Adjustments</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="tutorial8_files/libs/clipboard/clipboard.min.js"></script>
<script src="tutorial8_files/libs/quarto-html/quarto.js"></script>
<script src="tutorial8_files/libs/quarto-html/popper.min.js"></script>
<script src="tutorial8_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="tutorial8_files/libs/quarto-html/anchor.min.js"></script>
<link href="tutorial8_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="tutorial8_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="tutorial8_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="tutorial8_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="tutorial8_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#sec-intro" id="toc-sec-intro" class="nav-link active" data-scroll-target="#sec-intro"><span class="header-section-number">1</span> Introduction</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><span class="header-section-number">2</span> References</a></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Nonresponse Rates and Nonresponse Adjustments</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Quang Mai </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">March 6, 2024</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="sec-intro" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduction</h1>
<p>Please consider the Special Virtual Issue on Nonresponse Rates and Nonresponse Adjustments of the Journal of Survey Statistics and Methodology. Focus on one aspect of the editorial, and with reference to relevant literature, please discuss it in at least two pages. Use Quarto, and include an appropriate title, author, date, link to a GitHub repo, and citations. Submit a PDF.</p>
<p>The editorial of ‘Special Virtual Issue on Nonresponse Rates and Nonresponse Adjustments’ from the Journal of Survey Statistics and Methodology mainly talks about ways to evade unit and item nonresponse in data collection. Unit nonresponse occurs when a member of the data sample doesn’t respond to the survey, while item nonresponse happens when a member of the data sample fails to respond to one or more survey items that they are able to answer.</p>
<p>The main aim of sampling is to obtain accurate and timely estimates of key survey outcomes. Survey methodologists and statisticians exert significant control over survey processes at the design stage, aiming to minimize measurement and sampling errors. However, data collection introduces challenges such as unit and item nonresponse, necessitating remediation strategies. Understanding the survey response mechanism is crucial, as observed trends indicate declining response rates across various data collection modes, particularly with the rise of web surveys. Addressing nonresponse bias requires the identification of auxiliary variables predictive of both nonresponse and key survey variables. Papers in this collection explore methods for building nonresponse propensity models and post-data collection adjustments, including calibration weighting. They also discuss the performance of adjustment procedures such as poststratification and general calibration models. Additionally, there’s an emphasis on distinguishing between nonresponse mechanisms in the population and the sample, considering scenarios where nonresponse is not missing at random (NMAR). Techniques such as propensity-score-weighting and multiple imputation are explored for handling nonresponse, with considerations for incorporating survey weights in imputation models. Overall, these papers contribute to enhancing the accuracy of survey estimates through comprehensive methodological approaches.</p>
<p>The fundamental motivation for sampling is to obtain accurate and hopefully timely estimates of key survey outcomes. In theory, limiting the number of sampled units – as opposed to conducting a complete census – makes this possible. At the design stage, survey methodologists and statisticians have almost omniscient control over some parts of the survey process, for example, limiting measurement error via pretested questionnaires and sampling error via a probability sample design. Data collection changes everything, as some sampled units will not provide any data (unit nonresponse), and others will not always provide data for every queried item (item nonresponse). If the nonresponse is not related to the key survey variables, also known as missing completely at random (MCAR), then complete case analysis is often valid, if inefficient. In practice, however, this nonresponse condition rarely holds, and some form of remediation is necessary. Although changes to data collection strategies can help, statistical adjustments to the respondent-based estimates are often necessary. Understanding the nature of the survey response mechanism is fundamental to remediation, a recurring theme in JSSAM publications. This virtual issue, curated by JSSAM editors Kristen Olson and Katherine Jenny Thompson, presents a set of papers that address these issues.</p>
<p>First, we present a suite of papers that examine and codify changes in response rates, and accordingly, respondent composition, over time, across different modes of data collection (Williams and Brick 2018, Dutwin and Buskirk 2020, and Daikeler, Bošnjak, and Lozar Manfreda 2020). Overall, response rates are falling across all modes of data collection. Williams and Brick (2018) demonstrate declining response rates in both cross-sectional and the first round of longitudinal face-to-face national studies in the United States between 2000 and 2014. Dutwin and Buskirk (2020) turn the lens to four sets of cross-sectional national telephone surveys in the United States from 1996 to 2015. Response rates fell for each of these phone surveys, but weighted estimates from these studies showed no real change or a decrease in bias over the time period examined. Finally, Daikeler, Bošnjak, and Lozar Manfreda (2020) meta-analyze web survey response rates compared to response rates in other modes from experiments conducted between 1997 to 2016. They find that, uniformly, response rates to web modes are lower than that for other modes of data collection and that the difference between web and other modes stabilized between 2012 and 2016.</p>
<p>Together, these three papers confirm that the downward trend in response rates appears across modes and that the shift to web surveys is accelerating an industry-wide response rate decline. These papers also suggest areas for future work – have these trends continued through 2022 (and beyond)? Do changing response rates in face-to-face and/or web surveys yield similar shifts in biases that (may) be corrected by traditional weighting adjustments? How does variation in types of study designs affect response rates across modes of data collection, not just the discrepancy between web and other modes? Are the patterns observed by Williams and Brick (2018) and Dutwin and Buskirk (2020) observed in countries other than the US? As always, more work is needed.</p>
<p>It is well known that low response rates are not necessarily associated with nonresponse bias (e.g., Groves and Peytcheva 2008). Additionally, low response rates in selected subdomains (e.g., variation in response rates across age and education subgroups) are often used as indicators of systematic differences between respondents and nonrespondents on key estimates, although this association does not always hold (e.g., Peytcheva and Groves 2009). Nevertheless, assessing the existence and extent of such systematic differences between respondents and nonrespondents generally requires auxiliary variables that are available for all sample units and are highly predictive of all key outcomes. Ideally, these auxiliary variables can be used to not only evaluate the extent of nonresponse bias on estimates using these variables but also be included as independent variables in unit-level response propensity models. Predictions from well-specified models can serve a variety of purposes, including targeting potential nonrespondents via adaptive or responsive designs (Coffey, Reist and Miller 2020), assessing the response propensity deviation from MCAR via R-indicators (Schouten, et al.&nbsp;2011), or in nonresponse weighting adjustments (Kalton and Flores-Cervantes 2003). However, identifying good variables is harder in practice than it may seem, especially when there are weak auxiliary variables on sample frames. The next set of papers examine methods of building theory-driven nonresponse propensity models at the individual level. Wagner, Valliant, Hubbard, and Jiang (2014), Amaya and Harring (2017), and Peytchev, Presser, and Zhang (2018) take on this task.</p>
<p>Wagner, et al.&nbsp;(2014) show that, even though data collected about the data collection process (or paradata) are highly predictive of survey participation, these survey effort variables generate highly variable weights that had no effect on survey estimates of income, wealth, or health, insurance, or doctor visits in survey about health and economics. In contrast, through different methods and with different data sources, Amaya and Harring (2017) and Peytchev, Presser, and Zhang (2018) find that measures of civic engagement, including volunteering and voting, are associated with survey participation in longitudinal surveys and in cross-sectional surveys – volunteers and voters are more likely to participate. Although this association has been examined previously, these papers demonstrate the ability of these variables to predict participation (over other measures of integration) and/or improve adjustment methods, something that has received less attention. Notably, Peytchev, Presser, and Zhang (2018) also demonstrate the association between volunteering and voting and a wide variety of survey variables. Thus, including questions related to past voting history and/or current volunteering to surveys for purposes of nonresponse adjustment – even when not the main point of the survey and even with issues of overreporting for both behaviors - seem like low-hanging fruit to improve postsurvey adjustments.</p>
<p>Auxiliary variables that are both predictive of nonresponse and predictive of the key survey variables are useful for assessing the potential for nonresponse bias during and after data collection and for post-data collection adjustment procedures such as weighting and imputation (Little and Vartivarian 2005). The next paper discusses the usage of such auxiliary variables in measuring and remediating nonresponse, with a focus on post-data collection adjustment calibration weighting. Sӓrndal and Lundquist (2014) ask the important question of whether auxiliary variables that are available prior to data collection should be used to balance the sample during data collection (i.e., avoid systematic differences between respondents and nonrespondents) or through nonresponse adjustments after data collection. They propose methods for monitoring their Imbalance Statistic (a function of deviations between observed auxiliary variables for respondents and the full sample) and planning data collection interventions with the goal of reducing the variation in response propensities and thereby reduce sample imbalance. Through simulation with real survey data, they demonstrate that calibration nonresponse adjustments perform better when the set of respondents in the survey are more representative - that is, better balanced. Thus, incorporating both data collection adaptations and postsurvey adjustments seems to work better than either one alone.</p>
<p>The final set of papers in this virtual issue deal specifically with determining an appropriate post-data treatment for nonresponse. Han and Valliant (2021) assess conditions and performance of general calibration models and “popular” alternatives such as poststratification, raking, and general regression estimation on survey data with ignorable nonresponse. They evaluate these models analytically and through simulation with the ultimate goal of identifying the factors that contribute to the effectiveness of a selected adjustment procedure. The authors conclude that although interaction effects between the auxiliary variables are important in the determination of weighting methods, the most important factor is the overall predictive strength of the auxiliary variables used in the adjustment.</p>
<p>The next papers take a different view of nonresponse remediation. Berg, Kim, and Skinner (2016) consider both the response mechanism in the population and the response mechanism in the sample. The distinction between missing at random in the population (PMAR) and missing at random in the sample (SMAR) is especially important when the sampling design is informative (i.e., the sampling distribution is not representative of the population distribution, so the sample design cannot be ignored in finite population inference). With informative sampling, unbiased imputation parameters are generally obtained from models that include all design variables or the design weight. The authors demonstrate the pitfalls of this approach through simulation and propose an alternative approach that carefully conditions imputation on sample inclusion, then assuming only PMAR, using fractional imputation. The authors further present a replication procedure that obtains design-consistent variance estimators for the imputed estimates.</p>
<p>Adjustment cell weighting – as well as imputation – generally relies on the assumption that nonresponse is MCAR or missing-at-random (MAR). In contrast, Riddles, Kim, and Im (2016) consider a propensity-score-weighting approach under not missing at random (NMAR) response mechanism, proposing a form of maximum likelihood estimation based on the distributional assumptions of observed respondents instead of making unverifiable assumptions about the underlying population generation model for outcome and response. The authors test the robustness of their proposed approach in two simulation studies, and then apply their proposed methods to exit poll data.</p>
<p>Many of the nonresponse remediation techniques discussed in this issue use single-imputation or a weighting adjustment procedure. Such procedures are often operationally appealing, as they are simple to implement and yield a single estimate from the survey data. Alternatively, multiple imputation is appealing in that it both generates imputed values for missing data and provides a relatively simple variance estimator that appropriately accounts for imputation variance. That said, the inclusion of survey weights in multiple imputation models is not always straightforward. The issue concludes with Quartagno, Carpenter, and Goldstein (2019) who propose including weights in the imputation model, including interactions between the weights and the other variables in the model. The authors provide conditions that approximately satisfy the theoretical criterion for their approach under a MAR response mechanism, explored through comprehensive simulation and concluding with an empirical data application.</p>
</section>
<section id="references" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> References</h1>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>